{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ETL and analysis for e-commerce big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jeff Guo; Aug 18, 2016; guojianfu@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Outliers, data normalization and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we detect missing data, we first delete the entries that have too many missing data in differet dimentions. In the dog data, we will delete the entry with 22 NaNs.\n",
    "\n",
    "Before we try to detect outliers, usually we will do data normalization. Data normalization includes mean centering and feature scaling. Feature scaling has two ways, one way is to be divided by the range of the data, and another way is to be divided by standard deviation of the data.\n",
    "\n",
    "For a single feature, data normalization is not necessary.\n",
    "\n",
    "For hypothesis test, no matter univariate hypothesis test, multiple hypothesis test or multivariate hypothesis test, we don't need data normalization. However, if we do the data normalization based on each dimension, hypothesis test result will not be affected either. Especially, for the mutltivariate hypothesis testing, the shape of the data in high-dimentional space may look like an elliptical plate, but the projection to two orthometric axises may be both lines with the length of 1. Although the data normalization based on each dimension influences the covariances of different dimensions, the correlation coefficients of different dimensions will not be affected.\n",
    "\n",
    "For supervised mathematical modeling, such as linear regression, logistic regression, mixed effects logistic regression (linear mixed model) and artifical neural network, data normalization based on each dimension is necessary. After data normalization, gradient desent for objective optimization will be much faster.\n",
    "\n",
    "For unsupervised mathematical modeling, such as PCA, data normalization is also necessary. Data normalization based on each dimension influences the covariances of different columns of the dataframe, but it does not affect the correlation coefficients of different columns of the dataframe. PCA works on the correlation coefficient matrix not the coveriance matrix essentially. K-means clustering does not require data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note:\n",
    "\n",
    "PCA process is also line fitting, it is similar to linear correlation analysis, but it is different from linear regression. For objective function in linear regression, it tries to minimize the difference in y axis between the predicted value and the real value over the real value in y axis. For objective function in PCA process and linear correlation analysis, it tries to minimize the distance from the real data point to the fitted line over the distance between the real data point and the original point.\n",
    "\n",
    "Rank transform (sort the values and their ranks will be their rank transforms) can transform continuous data to categorical data. Other methods include binning transform (values in a range will be considered the same categorical data), K-means clustering, etc.\n",
    "\n",
    "Binning ransform and rank transform are both ordered categorical data (not simple string data). For ordered categorical data, they can be represented by one node in logistic regression or neural network (Just like continuous data). Of course, ordered categorical data can be further transformed to unordered categorical data, if so, they should be represented by a two-layer (or mutiple layer) subnetwork in logictic regression or neural  network. The first layer are all encoded as 0 or 1, the number of categories equals to the number of nodes in the first layer. The second layer contains only one node.\n",
    "\n",
    "Decision tree is also a kind of supervised mathematical modeling. Logistic regression is a two-layer neural network. For neural network, the predict variables can either be continuous variables or categorical variables, and the response variables can only be unordered catecorical variables. For decision tree, the predict variables can only be categorical variables (there may be range or inequalities for continuous variables, it is indeed ordered categorical variables), and the response variables can only be unordered categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's continue:\n",
    "\n",
    "After data normalization, we need description of each data dimention and the relations between different data dimentions.\n",
    "\n",
    "For categorical variables, we can use frequency table, bar chart (or stacked column bar chart), pie chart or bubble plot for the description of each data dimention. For continuous variables, we can use scatter plot, histogram, violin plot, box plot or violin plot with jittered data values for the description of each data dimention.\n",
    "\n",
    "For categorical vs. categorical, we can use bubble plot, chi-square test and fisher's exact test. For categorical vs. continuous, we can use boxplot, violin plot, t-test, z-test and one-way ANOVA. For continus vs. continuous, we can use scatter plot and linear correlation analysis.\n",
    "\n",
    "We can also visualize the high-dimentional data with PCA and correspoding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often do get the description of each data dimention. For continuous variables, if it is not normal distributuion and has skewed distributions, we will try log (natural log) scale transformation or square root scale transformation. After that, we will use box plot to detect outliers. Q1 is the first quartile and Q3 is the third quartile. Any value, which is beyond the range of Q1-1.5 x IQR to Q3+1.5 x IQR, will be regarded an outlier. IQR is interquartile range. \n",
    "\n",
    "Another criteria is: data points, three or more standard deviation away from mean are considered outlier. Outlier detection is merely a special case of the examination of data for influential data points and it also depends on the business understanding.\n",
    "\n",
    "The process to get the relations between different data dimentions and PCA can also be used to detect outliers. But usually we do not conduct this process at the beginning of the analysis, because the combination number will be large. For examle, if there are 30 dimentions, the number of relations between different data dimentions will be 30*29/2=435."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data normalization and outlier detection, sometimes, we will conduct the process of feature engineering. Here the feature engineering refers to creating a new feature from two or more old features.\n",
    "\n",
    "PCA is actually a process of feature engineering. The first principal component and the second principal component are both the linear combinations of old features. \n",
    "\n",
    "For multivariate hypothesis test and anomaly detection, you can either compute the covariance matrix and get the probability density (or probability that is as extreme as the value), or you can do multiple univariate hypothesis test with new features created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "xl = pd.ExcelFile(\"dognition_data_aggregated_by_dogid.xlsx\")\n",
    "df = xl.parse(\"dog_id_max_ranks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    a\n",
      "dtype: object\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    a\n",
      "dtype: category\n",
      "Categories (3, object): [a, b, c]\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    a\n",
      "dtype: category\n",
      "Categories (3, object): [a < b < c]\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    a\n",
      "dtype: category\n",
      "Categories (3, object): [c < b < a]\n",
      "0    NaN\n",
      "1      b\n",
      "2      c\n",
      "3    NaN\n",
      "dtype: category\n",
      "Categories (2, object): [c < b]\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    a\n",
      "dtype: object\n",
      "['a' 'b' 'c' 'a']\n",
      "<type 'numpy.ndarray'>\n",
      "object\n",
      "['b', 'a', 'b']\n",
      "0    Group a\n",
      "1    Group b\n",
      "2    Group c\n",
      "3    Group a\n",
      "dtype: category\n",
      "Categories (3, object): [Group a, Group b, Group c]\n",
      "Index([u'Group a', u'Group b', u'Group c'], dtype='object')\n",
      "<class 'pandas.indexes.base.Index'>\n",
      "['Group a', 'Group b', 'Group c']\n",
      "0    Group a\n",
      "1    Group b\n",
      "2    Group c\n",
      "3    Group a\n",
      "dtype: category\n",
      "Categories (3, object): [Group a < Group b < Group c]\n",
      "True\n",
      "Group a    2\n",
      "Group c    1\n",
      "Group b    1\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "set([dtype('bool')])\n",
      "int64\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df.head()\n",
    "df['Dog ID']\n",
    "s = df.ix[:,0]\n",
    "type(s)\n",
    "s\n",
    "s1 = df.ix[0,:]\n",
    "s1\n",
    "df.columns\n",
    "df.index\n",
    "df.columns.dtype\n",
    "s = pd.Series([\"a\",\"b\",\"c\",\"a\"])\n",
    "print s\n",
    "s2 = s.astype('category')\n",
    "print s2\n",
    "s2p = s.astype('category', ordered=True)\n",
    "print s2p\n",
    "s2pp = s.astype('category', categories=['c','b','a'], ordered=True)\n",
    "print s2pp\n",
    "s2ppp = s.astype('category', categories=['c','b'], ordered=True)\n",
    "print s2ppp\n",
    "s3 = s2.astype('string')\n",
    "print s3\n",
    "s4 = np.asarray(s2)\n",
    "print s4\n",
    "print type(s4)\n",
    "print s4.dtype\n",
    "print list('bab')\n",
    "s2.cat.categories = [\"Group %s\" % g for g in s2.cat.categories]\n",
    "print s2\n",
    "# s2.cat.ordered = True\n",
    "# print s2\n",
    "s2.cat.remove_unused_categories()\n",
    "print s2.cat.categories\n",
    "print type(s2.cat.categories)\n",
    "print s2.cat.categories.tolist()\n",
    "# Series.tolist(), Index.tolist(), np.array(Dataframe).tolist()\n",
    "# s2.cat.set_categories([\"one\",\"two\",\"three\",\"four\"])\n",
    "s22=s2.cat.as_ordered()\n",
    "print s22\n",
    "print s22.cat.ordered\n",
    "print s2.value_counts()\n",
    "print type(s2.value_counts())\n",
    "print set([pd.isnull(df.head())[y].dtype for y in pd.isnull(df.head()).columns])\n",
    "print df.index.dtype\n",
    "print df.index.dtype == np.int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog ID                                              object\n",
       "Total Tests Completed                                int64\n",
       "Mean ITI (days)                                    float64\n",
       "Mean ITI (minutes)                                 float64\n",
       "Median ITI (days)                                  float64\n",
       "Median ITI (minutes)                               float64\n",
       "Time diff between first and last game (days)       float64\n",
       "Time diff between first and last game (minutes)    float64\n",
       "User ID                                             object\n",
       "Gender                                              object\n",
       "Birthday                                           float64\n",
       "Breed                                               object\n",
       "Breed_Type                                          object\n",
       "Breed_Group                                         object\n",
       "Weight                                             float64\n",
       "Dog_Fixed                                          float64\n",
       "DNA_Tested                                         float64\n",
       "Dimension                                           object\n",
       "Sign_in_Count                                      float64\n",
       "Max_Dogs                                           float64\n",
       "Membership_ID                                      float64\n",
       "Subscribed                                         float64\n",
       "City                                                object\n",
       "State                                               object\n",
       "Zip                                                 object\n",
       "Country                                             object\n",
       "Exclude                                             object\n",
       "Free_Start_User                                     object\n",
       "Last_Active_At                                      object\n",
       "Membership_Type                                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "# object usually means string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Number of NaNs  Count\n",
      "0               0  11145\n",
      "1               1     46\n",
      "2               2     19\n",
      "3               3     89\n",
      "4               4   5832\n",
      "5               5      8\n",
      "6               7      9\n",
      "7               8    837\n",
      "8              22      1\n",
      "\n",
      "(17986, 30)\n",
      "\n",
      "16643\n",
      "\n",
      "(17986, 30)\n",
      "\n",
      "(17985, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num = np.sum(df.isnull().values, axis = 1).tolist()\n",
    "# print len(num)\n",
    "\n",
    "l1 = list(set(num))\n",
    "l1.sort()\n",
    "\n",
    "fre = {i:num.count(i) for i in l1}\n",
    "# print fre\n",
    "# print\n",
    "\n",
    "dt = pd.DataFrame(fre.items(), columns=['Number of NaNs', 'Count'])\n",
    "# or list(fre.items()) in python 3\n",
    "\n",
    "print dt\n",
    "print\n",
    "print df.shape\n",
    "print\n",
    "print num.index(22)\n",
    "print\n",
    "db = df.drop(df.index[[num.index(22)]])\n",
    "print df.shape\n",
    "print\n",
    "print db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "object\n",
      "17985\n",
      "1\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print db['Dog ID'].dtype\n",
    "db2 = db.copy()\n",
    "# db['Dog ID'].tolist()\n",
    "a = db2['Dog ID'].astype('category')\n",
    "print db['Dog ID'].dtype\n",
    "print db2['Dog ID'].dtype\n",
    "b = a.value_counts()\n",
    "# print b\n",
    "# print b.shape\n",
    "print b.shape[0]\n",
    "c=(1)\n",
    "print c\n",
    "d=(1,)\n",
    "print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17985, 45, 14705, 14705, 5870, 5870, 14181, 14181, 16261, 2, 26, 1326, 4, 8, 20, 2, 2, 10, 80, 15, 15, 2, 3398, 290, 6113, 68, 38, 36, 12558, 7]\n",
      "Dog ID                                             category\n",
      "Total Tests Completed                                 int64\n",
      "Mean ITI (days)                                     float64\n",
      "Mean ITI (minutes)                                  float64\n",
      "Median ITI (days)                                   float64\n",
      "Median ITI (minutes)                                float64\n",
      "Time diff between first and last game (days)        float64\n",
      "Time diff between first and last game (minutes)     float64\n",
      "User ID                                            category\n",
      "Gender                                             category\n",
      "Birthday                                            float64\n",
      "Breed                                              category\n",
      "Breed_Type                                         category\n",
      "Breed_Group                                        category\n",
      "Weight                                              float64\n",
      "Dog_Fixed                                           float64\n",
      "DNA_Tested                                          float64\n",
      "Dimension                                          category\n",
      "Sign_in_Count                                       float64\n",
      "Max_Dogs                                            float64\n",
      "Membership_ID                                       float64\n",
      "Subscribed                                          float64\n",
      "City                                               category\n",
      "State                                              category\n",
      "Zip                                                category\n",
      "Country                                            category\n",
      "Exclude                                            category\n",
      "Free_Start_User                                    category\n",
      "Last_Active_At                                     category\n",
      "Membership_Type                                    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "for y in db2.columns:\n",
    "    if db2[y].dtype == object:\n",
    "        db2[y] = db2[y].astype('category')    \n",
    "#[pd.isnull(df.head())[y].dtype for y in pd.isnull(df.head()).columns]\n",
    "print [db2[i].value_counts().shape[0] for i in db2.columns]\n",
    "print db2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Dog ID', u'User ID', u'Gender', u'Breed', u'Breed_Type', u'Breed_Group', u'Dimension', u'City', u'State', u'Zip', u'Country', u'Exclude', u'Free_Start_User', u'Last_Active_At', u'Membership_Type']\n"
     ]
    }
   ],
   "source": [
    "db['Dog ID'].dtype == object\n",
    "db['Total Tests Completed'].dtype == object\n",
    "print [i for i in db.columns if db[i].dtype == object]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "male      9352\n",
      "female    8633\n",
      "Name: Gender, dtype: int64\n",
      "\n",
      "Breed_Type\n",
      "Pure Breed                          9346\n",
      "Mixed Breed/ Other/ I Don't Know    4999\n",
      "Cross Breed                         2976\n",
      "Popular Hybrid                       664\n",
      "Name: Breed_Type, dtype: int64\n",
      "\n",
      "Breed_Group\n",
      "0               9055\n",
      "Sporting        2587\n",
      "Herding         1876\n",
      "Toy             1168\n",
      "Non-Sporting    1007\n",
      "Working          899\n",
      "Terrier          809\n",
      "Hound            584\n",
      "Name: Breed_Group, dtype: int64\n",
      "\n",
      "Dimension\n",
      "0                  13776\n",
      "socialite            871\n",
      "charmer              690\n",
      "protodog             602\n",
      "renaissance-dog      510\n",
      "ace                  477\n",
      "stargazer            361\n",
      "expert               298\n",
      "maverick             271\n",
      "einstein             129\n",
      "Name: Dimension, dtype: int64\n",
      "\n",
      "Membership_Type\n",
      "1     9129\n",
      "4     3874\n",
      "2     3735\n",
      "3      659\n",
      "0      502\n",
      "5       46\n",
      "CA      40\n",
      "Name: Membership_Type, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for y in db.columns:   \n",
    "    if db[y].dtype == object and db[y].value_counts().shape[0]<20:\n",
    "        # in python, logical operators are and, or\n",
    "        print y\n",
    "        print db[y].value_counts()\n",
    "        print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exclude\n",
      "38\n",
      "0      17828\n",
      "1        117\n",
      "V0N        3\n",
      "V6K        2\n",
      "K2E        2\n",
      "V6B        1\n",
      "N1H        1\n",
      "M6s        1\n",
      "L7S        1\n",
      "P1B        1\n",
      "N0C        1\n",
      "L3M        1\n",
      "L4C        1\n",
      "L4A        1\n",
      "v0n        1\n",
      "K8A        1\n",
      "K0k        1\n",
      "V0H        1\n",
      "M5a        1\n",
      "M5A        1\n",
      "N1E        1\n",
      "B3V        1\n",
      "L9G        1\n",
      "l4j        1\n",
      "M6K        1\n",
      "L5B        1\n",
      "V8T        1\n",
      "M4E        1\n",
      "v8r        1\n",
      "J0X        1\n",
      "L1M        1\n",
      "L1N        1\n",
      "m1e        1\n",
      "N6p        1\n",
      "L6M        1\n",
      "H3L        1\n",
      "V6N        1\n",
      "A1B        1\n",
      "Name: Exclude, dtype: int64\n",
      "\n",
      "Free_Start_User\n",
      "36\n",
      "0                                                                           13427\n",
      "1                                                                            4518\n",
      "North Island                                                                    4\n",
      "Downtown Toronto (Regent Park / Port of Toronto)                                2\n",
      "Vancouver (Central Kitsilano)                                                   2\n",
      "Nepean East                                                                     2\n",
      "North Bay Central                                                               1\n",
      "Stouffville                                                                     1\n",
      "South Okanagan (Summerland)                                                     1\n",
      "Whitby Southeast                                                                1\n",
      "Oakville West                                                                   1\n",
      "West Toronto (Brockton / Parkdale Village / Exhibition Place)                   1\n",
      "Guelph North                                                                    1\n",
      "Guelph Northwest                                                                1\n",
      "St. John's Northwest Newfoundland & Labrador Provincial Government              1\n",
      "East Toronto (The Beaches)                                                      1\n",
      "Grimsby                                                                         1\n",
      "Scarborough (Guildwood / Morningside / Ellesmere)                               1\n",
      "Quinte Shores                                                                   1\n",
      "Ahuntsic Southwest                                                              1\n",
      "Oak Bay North                                                                   1\n",
      "Georgian Bay Southwest Shore (Dundalk)                                          1\n",
      "Thornhill West                                                                  1\n",
      "Victoria North                                                                  1\n",
      "Burlington South                                                                1\n",
      "Mississauga (West Cooksville / Fairview / City Centre / East Creditview)        1\n",
      "Vancouver (NE Downtown / Harbour Centre / Gastown / Yaletown)                   1\n",
      "Vancouver (Dunbar- Southlands / Musqueam)                                       1\n",
      "London (Talbot / Lambeth / West Tempo / South Sharon Creek)                     1\n",
      "Whitby North                                                                    1\n",
      "West Toronto (Bloor West Village / Swansea)                                     1\n",
      "Richmond Hill Southwest                                                         1\n",
      "Harrietsfield                                                                   1\n",
      "Pembroke Central and northern subdivisions                                      1\n",
      "Outaouais-Sud (Thurso)                                                          1\n",
      "Ancaster West                                                                   1\n",
      "Name: Free_Start_User, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_some = ['Exclude','Free_Start_User']\n",
    "\n",
    "for x in col_some:\n",
    "    print x\n",
    "    print db[x].value_counts().shape[0]\n",
    "    print db[x].value_counts()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID\n",
      "16261\n",
      "\n",
      "Breed\n",
      "1326\n",
      "\n",
      "City\n",
      "3398\n",
      "\n",
      "State\n",
      "290\n",
      "\n",
      "Zip\n",
      "6113\n",
      "\n",
      "Country\n",
      "68\n",
      "\n",
      "Last_Active_At\n",
      "12558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "col_other = ['User ID','Breed','City','State','Zip','Country','Last_Active_At']        \n",
    "\n",
    "for x in col_other:\n",
    "    print x\n",
    "    print db[x].value_counts().shape[0]\n",
    "    print "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
